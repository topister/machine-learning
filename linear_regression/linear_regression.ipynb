{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【problem1】Hypothetical function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ScratchLinearRegression():\n",
    "    def __init__(self, num_iter, lr, no_bias=False, verbose=False):\n",
    "        # Initialize the number of iterations, learning rate, no_bias flag, and verbose flag\n",
    "        self.num_iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Prepare arrays to record the loss at each iteration\n",
    "        self.loss = np.zeros(self.num_iter)\n",
    "        self.val_loss = np.zeros(self.num_iter)\n",
    "        \n",
    "        # Placeholder for the coefficients (parameters), will be initialized during fit\n",
    "        self.coef_ = None\n",
    "\n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        Compute a linear hypothetical function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "          Training data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray, shape (n_samples,)\n",
    "          Estimated result by linear hypothetical function\n",
    "        \"\"\"\n",
    "        # Calculate the predicted values by taking the dot product of X and the coefficients\n",
    "        return np.dot(X, self.coef_)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # Add a bias term (column of ones) to the features if no_bias is False\n",
    "        if not self.no_bias:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "            if X_val is not None:\n",
    "                X_val = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
    "        \n",
    "        # Initialize the coefficients to zeros (including bias term if applicable)\n",
    "        self.coef_ = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            # Compute the predicted values for the current iteration\n",
    "            y_pred = self._linear_hypothesis(X)\n",
    "            \n",
    "            # Calculate the error as the difference between predicted and actual values\n",
    "            error = y_pred - y\n",
    "            \n",
    "            # Update the coefficients using the gradient descent update rule\n",
    "            self.coef_ -= self.lr * (2 / X.shape[0]) * np.dot(X.T, error)\n",
    "            \n",
    "            # Record the mean squared error for the training data\n",
    "            self.loss[i] = np.mean(error ** 2)\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                # Compute the predicted values for the validation data\n",
    "                y_val_pred = self._linear_hypothesis(X_val)\n",
    "                \n",
    "                # Calculate the validation error\n",
    "                val_error = y_val_pred - y_val\n",
    "                \n",
    "                # Record the mean squared error for the validation data\n",
    "                self.val_loss[i] = np.mean(val_error ** 2)\n",
    "            \n",
    "            # If verbose is True, print the training and validation loss for the current iteration\n",
    "            if self.verbose:\n",
    "                print(f\"Iteration {i+1}, Training loss: {self.loss[i]}\")\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    print(f\"Validation loss: {self.val_loss[i]}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a bias term (column of ones) to the features if no_bias is False\n",
    "        if not self.no_bias:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        \n",
    "        # Return the predicted values using the hypothetical function\n",
    "        return self._linear_hypothesis(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【problem2】Steepest descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ScratchLinearRegression():\n",
    "    def __init__(self, num_iter, lr, no_bias=False, verbose=False):\n",
    "        # Initialize the number of iterations, learning rate, no_bias flag, and verbose flag\n",
    "        self.num_iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Prepare arrays to record the loss at each iteration\n",
    "        self.loss = np.zeros(self.num_iter)\n",
    "        self.val_loss = np.zeros(self.num_iter)\n",
    "        \n",
    "        # Placeholder for the coefficients (parameters), will be initialized during fit\n",
    "        self.coef_ = None\n",
    "\n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        Compute a linear hypothetical function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "          Training data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray, shape (n_samples,)\n",
    "          Estimated result by linear hypothetical function\n",
    "        \"\"\"\n",
    "        # Calculate the predicted values by taking the dot product of X and the coefficients\n",
    "        return np.dot(X, self.coef_)\n",
    "\n",
    "    def _gradient_descent(self, X, error):\n",
    "        \"\"\"\n",
    "        Perform one step of gradient descent to update the coefficients\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "          Training data\n",
    "        error : ndarray, shape (n_samples,)\n",
    "          Difference between predicted and actual values\n",
    "\n",
    "        \"\"\"\n",
    "        # Update the coefficients based on the gradient of the loss function\n",
    "        self.coef_ -= self.lr * (2 / X.shape[0]) * np.dot(X.T, error)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # Add a bias term (column of ones) to the features if no_bias is False\n",
    "        if not self.no_bias:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "            if X_val is not None:\n",
    "                X_val = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
    "        \n",
    "        # Initialize the coefficients to zeros (including bias term if applicable)\n",
    "        self.coef_ = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            # Compute the predicted values for the current iteration\n",
    "            y_pred = self._linear_hypothesis(X)\n",
    "            \n",
    "            # Calculate the error as the difference between predicted and actual values\n",
    "            error = y_pred - y\n",
    "            \n",
    "            # Update the coefficients using the gradient descent method\n",
    "            self._gradient_descent(X, error)\n",
    "            \n",
    "            # Record the mean squared error for the training data\n",
    "            self.loss[i] = np.mean(error ** 2)\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                # Compute the predicted values for the validation data\n",
    "                y_val_pred = self._linear_hypothesis(X_val)\n",
    "                \n",
    "                # Calculate the validation error\n",
    "                val_error = y_val_pred - y_val\n",
    "                \n",
    "                # Record the mean squared error for the validation data\n",
    "                self.val_loss[i] = np.mean(val_error ** 2)\n",
    "            \n",
    "            # If verbose is True, print the training and validation loss for the current iteration\n",
    "            if self.verbose:\n",
    "                print(f\"Iteration {i+1}, Training loss: {self.loss[i]}\")\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    print(f\"Validation loss: {self.val_loss[i]}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a bias term (column of ones) to the features if no_bias is False\n",
    "        if not self.no_bias:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        \n",
    "        # Return the predicted values using the hypothetical function\n",
    "        return self._linear_hypothesis(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【problem 3】Estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ScratchLinearRegression():\n",
    "    def __init__(self, num_iter, lr, no_bias=False, verbose=False):\n",
    "        # Initialize the number of iterations, learning rate, no_bias flag, and verbose flag\n",
    "        self.num_iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Prepare arrays to record the loss at each iteration\n",
    "        self.loss = np.zeros(self.num_iter)\n",
    "        self.val_loss = np.zeros(self.num_iter)\n",
    "        \n",
    "        # Placeholder for the coefficients (parameters), will be initialized during fit\n",
    "        self.coef_ = None\n",
    "\n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        Compute a linear hypothetical function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "          Training data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray, shape (n_samples,)\n",
    "          Estimated result by linear hypothetical function\n",
    "        \"\"\"\n",
    "        # Calculate the predicted values by taking the dot product of X and the coefficients\n",
    "        return np.dot(X, self.coef_)\n",
    "\n",
    "    def _gradient_descent(self, X, error):\n",
    "        \"\"\"\n",
    "        Perform one step of gradient descent to update the coefficients\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "          Training data\n",
    "        error : ndarray, shape (n_samples,)\n",
    "          Difference between predicted and actual values\n",
    "\n",
    "        \"\"\"\n",
    "        # Update the coefficients based on the gradient of the loss function\n",
    "        self.coef_ -= self.lr * (2 / X.shape[0]) * np.dot(X.T, error)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # Add a bias term (column of ones) to the features if no_bias is False\n",
    "        if not self.no_bias:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "            if X_val is not None:\n",
    "                X_val = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
    "        \n",
    "        # Initialize the coefficients to zeros (including bias term if applicable)\n",
    "        self.coef_ = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            # Compute the predicted values for the current iteration\n",
    "            y_pred = self._linear_hypothesis(X)\n",
    "            \n",
    "            # Calculate the error as the difference between predicted and actual values\n",
    "            error = y_pred - y\n",
    "            \n",
    "            # Update the coefficients using the gradient descent method\n",
    "            self._gradient_descent(X, error)\n",
    "            \n",
    "            # Record the mean squared error for the training data\n",
    "            self.loss[i] = np.mean(error ** 2)\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                # Compute the predicted values for the validation data\n",
    "                y_val_pred = self._linear_hypothesis(X_val)\n",
    "                \n",
    "                # Calculate the validation error\n",
    "                val_error = y_val_pred - y_val\n",
    "                \n",
    "                # Record the mean squared error for the validation data\n",
    "                self.val_loss[i] = np.mean(val_error ** 2)\n",
    "            \n",
    "            # If verbose is True, print the training and validation loss for the current iteration\n",
    "            if self.verbose:\n",
    "                print(f\"Iteration {i+1}, Training loss: {self.loss[i]}\")\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    print(f\"Validation loss: {self.val_loss[i]}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a bias term (column of ones) to the features if no_bias is False\n",
    "        if not self.no_bias:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        \n",
    "        # Return the predicted values using the hypothetical function\n",
    "        return self._linear_hypothesis(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【problem 4】Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    Calculation of mean square error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : ndarray, shape (n_samples,)\n",
    "      Estimated value\n",
    "    y : ndarray, shape (n_samples,)\n",
    "      Correct answer value\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      Mean squared error\n",
    "    \"\"\"\n",
    "    # Calculate the squared differences between predicted and actual values\n",
    "    squared_errors = (y_pred - y) ** 2\n",
    "    \n",
    "    # Calculate the mean squared error\n",
    "    mse = np.mean(squared_errors)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【problem 5】Objective function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ScratchLinearRegression():\n",
    "    def __init__(self, num_iter, lr, no_bias=False, verbose=False):\n",
    "        # Initialize the number of iterations, learning rate, no_bias flag, and verbose flag\n",
    "        self.num_iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Prepare arrays to record the loss at each iteration\n",
    "        self.loss = np.zeros(self.num_iter)\n",
    "        self.val_loss = np.zeros(self.num_iter)\n",
    "        \n",
    "        # Placeholder for the coefficients (parameters), will be initialized during fit\n",
    "        self.coef_ = None\n",
    "\n",
    "    \n",
    "\n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        Compute a linear hypothetical function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "          Training data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray, shape (n_samples,)\n",
    "          Estimated result by linear hypothetical function\n",
    "        \"\"\"\n",
    "        # # Convert X to a NumPy array if it's not already\n",
    "        # X = np.array(X)\n",
    "    \n",
    "        # # Print the shapes of X and coefficients for debugging\n",
    "        # print(\"Shape of X:\", X.shape)\n",
    "        # print(\"Shape of coefficients:\", self.coef_.shape)\n",
    "        # print(\"Type of elements in coefficients:\", self.coef_.dtype)\n",
    "\n",
    "    \n",
    "        # # Calculate the predicted values by taking the dot product of X and the coefficients\n",
    "        # y_pred = np.dot(X, self.coef_)\n",
    "    \n",
    "        # return y_pred\n",
    "\n",
    "        # Convert X to a NumPy array if it's not already\n",
    "        X = np.array(X)\n",
    "    \n",
    "        # Print the shapes of X and coefficients for debugging\n",
    "        print(\"Shape of X:\", X.shape)\n",
    "        print(\"Shape of coefficients:\", self.coef_.shape)\n",
    "    \n",
    "        # Print the intermediate result of the dot product\n",
    "        dot_product_result = np.dot(X, self.coef_)\n",
    "        print(\"Shape of dot product result:\", dot_product_result.shape)\n",
    "    \n",
    "        # Calculate the predicted values by taking the dot product of X and the coefficients\n",
    "        y_pred = dot_product_result\n",
    "    \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "\n",
    "    def _gradient_descent(self, X, error):\n",
    "        \"\"\"\n",
    "        Perform one step of gradient descent to update the coefficients\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "          Training data\n",
    "        error : ndarray, shape (n_samples,)\n",
    "          Difference between predicted and actual values\n",
    "\n",
    "        \"\"\"\n",
    "        # Update the coefficients based on the gradient of the loss function\n",
    "        # self.coef_ -= self.lr * (2 / X.shape[0]) * np.dot(X.T, error)\n",
    "        # Update the coefficients based on the gradient of the loss function\n",
    "        self.coef_ -= self.lr * (2 / X.shape[0]) * np.dot(X.T, error)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Learn linear regression. If validation data is entered, the loss and accuracy for it are also calculated for each iteration.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : ndarray, shape (n_samples, )\n",
    "            Correct answer value of training data\n",
    "        X_val : ndarray, shape (n_samples, n_features)\n",
    "            Features of validation data\n",
    "        y_val : ndarray, shape (n_samples, )\n",
    "            Correct value of validation data\n",
    "        \"\"\"\n",
    "        if not self.no_bias:\n",
    "            # Add a bias term (column of ones) to the features if no_bias is False\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "            if X_val is not None:\n",
    "                X_val = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
    "\n",
    "        # Initialize the coefficients to zeros (including bias term if applicable)\n",
    "        self.coef_ = np.zeros(X.shape[1])\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            # Compute the predicted values for the current iteration\n",
    "            y_pred = self._linear_hypothesis(X)\n",
    "\n",
    "            # Calculate the error as the difference between predicted and actual values\n",
    "            error = y_pred - y\n",
    "\n",
    "            # Update the coefficients using the gradient descent method\n",
    "            self._gradient_descent(X, error)\n",
    "\n",
    "            # Record the mean squared error for the training data\n",
    "            self.loss[i] = np.mean(error ** 2)\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                # Compute the predicted values for the validation data\n",
    "                y_val_pred = self._linear_hypothesis(X_val)\n",
    "\n",
    "                # Calculate the validation error\n",
    "                val_error = y_val_pred - y_val\n",
    "\n",
    "                # Record the mean squared error for the validation data\n",
    "                self.val_loss[i] = np.mean(val_error ** 2)\n",
    "\n",
    "            # If verbose is True, print the training and validation loss for the current iteration\n",
    "            if self.verbose:\n",
    "                print(f\"Iteration {i + 1}, Training loss: {self.loss[i]}\")\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    print(f\"Validation loss: {self.val_loss[i]}\")\n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a bias term (column of ones) to the features if no_bias is False\n",
    "        if not self.no_bias:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        \n",
    "        # Return the predicted values using the hypothetical function\n",
    "        return self._linear_hypothesis(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 6 Learning and Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the target variable\n",
    "target_variable = \"SalePrice\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Numerical features:  38\n",
      "Number of Categorical features:  43\n"
     ]
    }
   ],
   "source": [
    "numerical_features = data.dtypes[data.dtypes != \"object\"].index\n",
    "print(\"Number of Numerical features: \", len(numerical_features))\n",
    "\n",
    "categorical_features = data.dtypes[data.dtypes == \"object\"].index\n",
    "print(\"Number of Categorical features: \", len(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "                ... \n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "SalePrice          0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0.000000\n",
       "MSSubClass        0.000000\n",
       "MSZoning          0.000000\n",
       "LotFrontage      17.739726\n",
       "LotArea           0.000000\n",
       "                   ...    \n",
       "MoSold            0.000000\n",
       "YrSold            0.000000\n",
       "SaleType          0.000000\n",
       "SaleCondition     0.000000\n",
       "SalePrice         0.000000\n",
       "Length: 81, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_percentage = (missing_values / len(data)) * 100\n",
    "missing_values_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values for Each Feature:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>missing_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>17.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>93.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotShape</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandContour</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotConfig</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BldgType</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseStyle</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofStyle</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior1st</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior2nd</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>872</td>\n",
       "      <td>59.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterQual</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterCond</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foundation</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total  missing_ratio\n",
       "Id                0       0.000000\n",
       "MSSubClass        0       0.000000\n",
       "MSZoning          0       0.000000\n",
       "LotFrontage     259      17.739726\n",
       "LotArea           0       0.000000\n",
       "Street            0       0.000000\n",
       "Alley          1369      93.767123\n",
       "LotShape          0       0.000000\n",
       "LandContour       0       0.000000\n",
       "Utilities         0       0.000000\n",
       "LotConfig         0       0.000000\n",
       "LandSlope         0       0.000000\n",
       "Neighborhood      0       0.000000\n",
       "Condition1        0       0.000000\n",
       "Condition2        0       0.000000\n",
       "BldgType          0       0.000000\n",
       "HouseStyle        0       0.000000\n",
       "OverallQual       0       0.000000\n",
       "OverallCond       0       0.000000\n",
       "YearBuilt         0       0.000000\n",
       "YearRemodAdd      0       0.000000\n",
       "RoofStyle         0       0.000000\n",
       "RoofMatl          0       0.000000\n",
       "Exterior1st       0       0.000000\n",
       "Exterior2nd       0       0.000000\n",
       "MasVnrType      872      59.726027\n",
       "MasVnrArea        8       0.547945\n",
       "ExterQual         0       0.000000\n",
       "ExterCond         0       0.000000\n",
       "Foundation        0       0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = pd.DataFrame({'Total': missing_values, 'missing_ratio': missing_values_percentage})\n",
    "print(\"Missing Values for Each Feature:\")\n",
    "missing_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After dropping features with 5 or more missing values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "0   1          60       RL     8450   Pave      Reg         Lvl    AllPub   \n",
       "1   2          20       RL     9600   Pave      Reg         Lvl    AllPub   \n",
       "2   3          60       RL    11250   Pave      IR1         Lvl    AllPub   \n",
       "3   4          70       RL     9550   Pave      IR1         Lvl    AllPub   \n",
       "4   5          60       RL    14260   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "  LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch PoolArea  \\\n",
       "0    Inside       Gtl  ...             0         0           0        0   \n",
       "1       FR2       Gtl  ...             0         0           0        0   \n",
       "2    Inside       Gtl  ...             0         0           0        0   \n",
       "3    Corner       Gtl  ...           272         0           0        0   \n",
       "4       FR2       Gtl  ...             0         0           0        0   \n",
       "\n",
       "  MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0       0       2    2008        WD         Normal    208500  \n",
       "1       0       5    2007        WD         Normal    181500  \n",
       "2       0       9    2008        WD         Normal    223500  \n",
       "3       0       2    2006        WD        Abnorml    140000  \n",
       "4       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete features (columns) that have 5 or more missing values\n",
    "columns_to_drop = missing_df[missing_df['Total'] >= 5].index\n",
    "df_cleaned = data.drop(columns=columns_to_drop)\n",
    "print(\"\\nAfter dropping features with 5 or more missing values:\")\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df_cleaned.drop(columns=['SalePrice'])  # Features\n",
    "y = df_cleaned['SalePrice']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1168, 63)\n",
      "Shape of coefficients: (63,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model_scratch \u001b[38;5;241m=\u001b[39m ScratchLinearRegression(num_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel_scratch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Make predictions on the testing data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_pred_scratch \u001b[38;5;241m=\u001b[39m model_scratch\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mvalues)\n",
      "Cell \u001b[1;32mIn[5], line 108\u001b[0m, in \u001b[0;36mScratchLinearRegression.fit\u001b[1;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iter):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Compute the predicted values for the current iteration\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_linear_hypothesis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Calculate the error as the difference between predicted and actual values\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     error \u001b[38;5;241m=\u001b[39m y_pred \u001b[38;5;241m-\u001b[39m y\n",
      "Cell \u001b[1;32mIn[5], line 56\u001b[0m, in \u001b[0;36mScratchLinearRegression._linear_hypothesis\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of coefficients:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Print the intermediate result of the dot product\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m dot_product_result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of dot product result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dot_product_result\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Calculate the predicted values by taking the dot product of X and the coefficients\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "# Instantiate the ScratchLinearRegression class\n",
    "model_scratch = ScratchLinearRegression(num_iter=1000, lr=0.01, verbose=True)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model_scratch.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_scratch = model_scratch.predict(X_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
