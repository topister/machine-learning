{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【Problem 1】Creating a 2-D convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = np.random.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        self.b = np.zeros((out_channels, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Retrieve dimensions\n",
    "        N, C, H, W = x.shape\n",
    "        F, _, HH, WW = self.W.shape\n",
    "        stride = 1  # Assuming stride=1 for simplicity\n",
    "        pad = 0  # Assuming no padding for simplicity\n",
    "\n",
    "        # Calculate output dimensions\n",
    "        out_h = 1 + (H + 2 * pad - HH) // stride\n",
    "        out_w = 1 + (W + 2 * pad - WW) // stride\n",
    "\n",
    "        # Initialize output array\n",
    "        out = np.zeros((N, F, out_h, out_w))\n",
    "\n",
    "        # Pad input array\n",
    "        x_padded = np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "\n",
    "        # Perform convolution\n",
    "        for n in range(N):\n",
    "            for f in range(F):\n",
    "                for i in range(out_h):\n",
    "                    for j in range(out_w):\n",
    "                        # Extract the region of interest from the padded input\n",
    "                        x_slice = x_padded[n, :, i * stride:i * stride + HH, j * stride:j * stride + WW]\n",
    "                        # Perform the convolution operation and add bias\n",
    "                        out[n, f, i, j] = np.sum(x_slice * self.W[f]) + self.b[f]\n",
    "\n",
    "        self.output = out  # Store output for later use in backward pass\n",
    "        return out\n",
    "\n",
    "    def backward(self, delta):\n",
    "        # Retrieve dimensions\n",
    "        N, F, out_h, out_w = delta.shape\n",
    "        _, C, HH, WW = self.W.shape\n",
    "\n",
    "        # Initialize gradients\n",
    "        dx = np.zeros_like(delta)\n",
    "        dW = np.zeros_like(self.W)\n",
    "        db = np.zeros_like(self.b)\n",
    "\n",
    "        # Pad input array\n",
    "        x_padded = np.pad(self.input, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "\n",
    "        # Compute gradients\n",
    "        for n in range(N):\n",
    "            for f in range(F):\n",
    "                for i in range(out_h):\n",
    "                    for j in range(out_w):\n",
    "                        # Extract the region of interest from the padded input\n",
    "                        x_slice = x_padded[n, :, i * stride:i * stride + HH, j * stride:j * stride + WW]\n",
    "                        # Update gradients for weights and biases\n",
    "                        dW[f] += x_slice * delta[n, f, i, j]\n",
    "                        db[f] += delta[n, f, i, j]\n",
    "                        dx[n, :, i * stride:i * stride + HH, j * stride:j * stride + WW] += self.W[f] * delta[n, f, i, j]\n",
    "\n",
    "        # Remove padding from dx\n",
    "        dx = dx[:, :, pad:-pad, pad:-pad]\n",
    "\n",
    "        return dx, dW, db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Problem 2] Experiments with 2D convolutional layers on small arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the provided input and expected output\n",
    "x = np.array([[[[ 1,  2,  3,  4],\n",
    "                [ 5,  6,  7,  8],\n",
    "                [ 9, 10, 11, 12],\n",
    "                [13, 14, 15, 16]]]])\n",
    "\n",
    "W = np.array([[[ 0.,  0.,  0.],\n",
    "               [ 0.,  1.,  0.],\n",
    "               [ 0., -1.,  0.]],\n",
    "\n",
    "              [[ 0.,  0.,  0.],\n",
    "               [ 0., -1.,  1.],\n",
    "               [ 0.,  0.,  0.]]])\n",
    "\n",
    "# Dummy delta for backward propagation test\n",
    "delta = np.array([[[ -4,  -4],\n",
    "                   [ 10,  11]],\n",
    "\n",
    "                  [[  1,  -7],\n",
    "                   [  1, -11]]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Propagation Output:\n",
      "[[[[ 14.63997078  13.54600775]\n",
      "   [ 10.26411867   9.17015565]]\n",
      "\n",
      "  [[-14.21891663 -15.55630623]\n",
      "   [-19.568475   -20.9058646 ]]]]\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Forward Propagation Test Failed!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 106\u001b[0m\n\u001b[1;32m     99\u001b[0m expected_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m    100\u001b[0m                              [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]],\n\u001b[1;32m    101\u001b[0m                             \n\u001b[1;32m    102\u001b[0m                             [[ \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    103\u001b[0m                              [ \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;241m1\u001b[39m]]])\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Verify forward propagation\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(output, expected_output), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward Propagation Test Failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward Propagation Test Passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Forward Propagation Test Failed!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = np.random.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        self.b = np.zeros((out_channels, 1))\n",
    "        self.output = None  # Initialize output attribute\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Retrieve dimensions\n",
    "        N, C, H, W = x.shape\n",
    "        F, _, HH, WW = self.W.shape\n",
    "        stride = 1  # Assuming stride=1 for simplicity\n",
    "        pad = 0  # Assuming no padding for simplicity\n",
    "\n",
    "        # Calculate output dimensions\n",
    "        out_h = H - HH + 1\n",
    "        out_w = W - WW + 1\n",
    "\n",
    "        # Initialize output array\n",
    "        out = np.zeros((N, F, out_h, out_w))\n",
    "\n",
    "        # Perform convolution\n",
    "        for n in range(N):\n",
    "            for f in range(F):\n",
    "                for i in range(out_h):\n",
    "                    for j in range(out_w):\n",
    "                        # Extract the region of interest from the input\n",
    "                        x_slice = x[n, :, i:i+HH, j:j+WW]\n",
    "                        # Perform the convolution operation and add bias\n",
    "                        out[n, f, i, j] = np.sum(x_slice * self.W[f]) + self.b[f][0]\n",
    "\n",
    "        self.output = out  # Store output for later use in backward pass\n",
    "        return out\n",
    "\n",
    "    def backward(self, delta):\n",
    "        # Retrieve dimensions\n",
    "        N, F, out_h, out_w = delta.shape\n",
    "        _, C, HH, WW = self.W.shape\n",
    "\n",
    "        # Initialize gradients\n",
    "        dx = np.zeros_like(delta)\n",
    "        dW = np.zeros_like(self.W)\n",
    "        db = np.zeros_like(self.b)\n",
    "\n",
    "        # Pad input array\n",
    "        x_padded = np.pad(self.input, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "\n",
    "        # Compute gradients\n",
    "        for n in range(N):\n",
    "            for f in range(F):\n",
    "                for i in range(out_h):\n",
    "                    for j in range(out_w):\n",
    "                        # Extract the region of interest from the padded input\n",
    "                        x_slice = x_padded[n, :, i * stride:i * stride + HH, j * stride:j * stride + WW]\n",
    "                        # Update gradients for weights and biases\n",
    "                        dW[f] += x_slice * delta[n, f, i, j]\n",
    "                        db[f] += delta[n, f, i, j]\n",
    "                        dx[n, :, i * stride:i * stride + HH, j * stride:j * stride + WW] += self.W[f] * delta[n, f, i, j]\n",
    "\n",
    "        # Remove padding from dx\n",
    "        dx = dx[:, :, pad:-pad, pad:-pad]\n",
    "\n",
    "        return dx, dW, db\n",
    "\n",
    "\n",
    "# Test with the provided input and expected output\n",
    "x = np.array([[[[ 1,  2,  3,  4],\n",
    "                [ 5,  6,  7,  8],\n",
    "                [ 9, 10, 11, 12],\n",
    "                [13, 14, 15, 16]]]])\n",
    "\n",
    "W = np.array([[[ 0.,  0.,  0.],\n",
    "               [ 0.,  1.,  0.],\n",
    "               [ 0., -1.,  0.]],\n",
    "\n",
    "              [[ 0.,  0.,  0.],\n",
    "               [ 0., -1.,  1.],\n",
    "               [ 0.,  0.,  0.]]])\n",
    "\n",
    "# Dummy delta for backward propagation test\n",
    "delta = np.array([[[ -4,  -4],\n",
    "                   [ 10,  11]],\n",
    "\n",
    "                  [[  1,  -7],\n",
    "                   [  1, -11]]])\n",
    "\n",
    "# Test forward propagation\n",
    "conv_layer = Conv2d(in_channels=1, out_channels=2, kernel_size=3)\n",
    "output = conv_layer.forward(x)\n",
    "print(\"Forward Propagation Output:\")\n",
    "print(output)\n",
    "print()\n",
    "\n",
    "# Expected output from the problem statement\n",
    "expected_output = np.array([[[-4, -4],\n",
    "                             [-4, -4]],\n",
    "                            \n",
    "                            [[ 1,  1],\n",
    "                             [ 1,  1]]])\n",
    "\n",
    "# Verify forward propagation\n",
    "assert np.allclose(output, expected_output), \"Forward Propagation Test Failed!\"\n",
    "print(\"Forward Propagation Test Passed!\")\n",
    "print()\n",
    "\n",
    "# Test backward propagation\n",
    "dx, dW, db = conv_layer.backward(delta)\n",
    "print(\"Backward Propagation Gradients:\")\n",
    "print(\"dx:\")\n",
    "print(dx)\n",
    "print(\"dW:\")\n",
    "print(dW)\n",
    "print(\"db:\")\n",
    "print(db)\n",
    "print()\n",
    "\n",
    "# Expected gradients from the problem statement\n",
    "expected_dx = np.array([[[[  0.,   0.,   0.,   0.],\n",
    "                         [  0.,  -4.,   4.,   0.],\n",
    "                         [  0.,  -5.,  10.,  -5.],\n",
    "                         [  0.,   4.,  13.,   9.]]]])\n",
    "\n",
    "expected_dW = np.array([[[[ 21., 29., 19.],\n",
    "                          [ 27., 37., 24.],\n",
    "                          [ 18., 24., 15.]]],\n",
    "                        \n",
    "                        [[[-15., -7.,  0.],\n",
    "                          [ -9., -3.,  6.],\n",
    "                          [-18., -6.,  0.]]]])\n",
    "\n",
    "expected_db = np.array([[[-10.],\n",
    "                         [ 12.]]])\n",
    "\n",
    "# Verify backward propagation\n",
    "assert np.allclose(dx, expected_dx), \"Backward Propagation dx Test Failed!\"\n",
    "assert np.allclose(dW, expected_dW), \"Backward Propagation dW Test Failed!\"\n",
    "assert np.allclose(db, expected_db), \"Backward Propagation db Test Failed!\"\n",
    "print(\"Backward Propagation Test Passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Propagation Output:\n",
      "[[[[ 2.74008596  4.83831822]\n",
      "   [11.133015   13.23124726]]\n",
      "\n",
      "  [[ 5.42397905  7.05288599]\n",
      "   [11.93960679 13.56851372]]]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12674/2243464237.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  out[n, f, i, j] = np.sum(x_slice * self.W[f]) + self.b[f]\n"
     ]
    }
   ],
   "source": [
    "# Test forward propagation\n",
    "conv_layer = Conv2d(in_channels=1, out_channels=2, kernel_size=3)\n",
    "output = conv_layer.forward(x)\n",
    "print(\"Forward Propagation Output:\")\n",
    "print(output)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Forward Propagation Test Failed!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m expected_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m      3\u001b[0m                              [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]],\n\u001b[1;32m      4\u001b[0m                             \n\u001b[1;32m      5\u001b[0m                             [[ \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      6\u001b[0m                              [ \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;241m1\u001b[39m]]])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Verify forward propagation\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(output, expected_output), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward Propagation Test Failed!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward Propagation Test Passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Forward Propagation Test Failed!"
     ]
    }
   ],
   "source": [
    "# Expected output from the problem statement\n",
    "expected_output = np.array([[[-4, -4],\n",
    "                             [-4, -4]],\n",
    "                            \n",
    "                            [[ 1,  1],\n",
    "                             [ 1,  1]]])\n",
    "\n",
    "# Verify forward propagation\n",
    "assert np.allclose(output, expected_output), \"Forward Propagation Test Failed!\"\n",
    "print(\"Forward Propagation Test Passed!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
