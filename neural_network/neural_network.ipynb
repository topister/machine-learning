{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: h5py in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: absl-py in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: numpy in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras) (23.2)\n",
      "Requirement already satisfied: optree in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from optree->keras) (4.12.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m348.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:09\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m807.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: packaging in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m657.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m551.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: setuptools in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (4.12.0)\n",
      "Collecting tensorboard<2.17,>=2.16\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m512.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m514.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.5.tar.gz (26 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from tensorflow) (2.32.2)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: namex in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rich in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 KB\u001b[0m \u001b[31m634.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/topister/Desktop/dpro/machine-learning/dpro/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Using legacy 'setup.py install' for gast, since package 'wheel' is not installed.\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, opt-einsum, ml-dtypes, markdown, grpcio, google-pasta, gast, tensorboard, astunparse, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.0\n",
      "    Uninstalling ml-dtypes-0.4.0:\n",
      "      Successfully uninstalled ml-dtypes-0.4.0\n",
      "  Running setup.py install for gast ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.5 google-pasta-0.2.0 grpcio-1.64.1 libclang-18.1.1 markdown-3.6 ml-dtypes-0.3.2 opt-einsum-3.3.0 protobuf-4.25.3 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0 werkzeug-3.0.3 wheel-0.43.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 16:39:26.587491: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-27 16:39:27.811445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    def __init__(self, X, y, batch_size=20):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self._shuffle()\n",
    "        self.current_idx = 0\n",
    "\n",
    "    def _shuffle(self):\n",
    "        p = np.random.permutation(len(self.X))\n",
    "        self.X, self.y = self.X[p], self.y[p]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current_idx >= len(self):\n",
    "            self._shuffle()\n",
    "            self.current_idx = 0\n",
    "            raise StopIteration\n",
    "        idx = self.current_idx * self.batch_size\n",
    "        self.current_idx += 1\n",
    "        return self.X[idx:idx + self.batch_size], self.y[idx:idx + self.batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetworkClassifier():\n",
    "    def __init__(self, n_features=784, n_nodes1=400, n_nodes2=200, n_output=10, learning_rate=0.01, sigma=0.01, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.lr = learning_rate\n",
    "        self.sigma = sigma\n",
    "        self.W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "        self.B1 = np.zeros(n_nodes1)\n",
    "        self.W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        self.B2 = np.zeros(n_nodes2)\n",
    "        self.W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
    "        self.B3 = np.zeros(n_output)\n",
    "\n",
    "    def _sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    def _softmax(self, X):\n",
    "        exp_X = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "        return exp_X / np.sum(exp_X, axis=1, keepdims=True)\n",
    "\n",
    "    def _cross_entropy_error(self, y, t):\n",
    "        delta = 1e-7\n",
    "        return -np.sum(t * np.log(y + delta)) / y.shape[0]\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epochs=50, batch_size=20):\n",
    "        for epoch in range(epochs):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=batch_size)\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # Forward Propagation\n",
    "                A1 = np.dot(mini_X_train, self.W1) + self.B1\n",
    "                Z1 = self._sigmoid(A1)\n",
    "                A2 = np.dot(Z1, self.W2) + self.B2\n",
    "                Z2 = self._sigmoid(A2)\n",
    "                A3 = np.dot(Z2, self.W3) + self.B3\n",
    "                Z3 = self._softmax(A3)\n",
    "\n",
    "                # Back Propagation\n",
    "                dA3 = (Z3 - mini_y_train) / batch_size\n",
    "                self.W3 -= self.lr * np.dot(Z2.T, dA3)\n",
    "                self.B3 -= self.lr * np.sum(dA3, axis=0)\n",
    "\n",
    "                dZ2 = np.dot(dA3, self.W3.T) * Z2 * (1 - Z2)\n",
    "                self.W2 -= self.lr * np.dot(Z1.T, dZ2)\n",
    "                self.B2 -= self.lr * np.sum(dZ2, axis=0)\n",
    "\n",
    "                dZ1 = np.dot(dZ2, self.W2.T) * Z1 * (1 - Z1)\n",
    "                self.W1 -= self.lr * np.dot(mini_X_train.T, dZ1)\n",
    "                self.B1 -= self.lr * np.sum(dZ1, axis=0)\n",
    "\n",
    "            if self.verbose:\n",
    "                A1 = np.dot(X_val, self.W1) + self.B1\n",
    "                Z1 = self._sigmoid(A1)\n",
    "                A2 = np.dot(Z1, self.W2) + self.B2\n",
    "                Z2 = self._sigmoid(A2)\n",
    "                A3 = np.dot(Z2, self.W3) + self.B3\n",
    "                Z3 = self._softmax(A3)\n",
    "                loss = self._cross_entropy_error(Z3, y_val)\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Loss: {loss}')\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        A1 = np.dot(X, self.W1) + self.B1\n",
    "        Z1 = self._sigmoid(A1)\n",
    "        A2 = np.dot(Z1, self.W2) + self.B2\n",
    "        Z2 = self._sigmoid(A2)\n",
    "        A3 = np.dot(Z2, self.W3) + self.B3\n",
    "        Z3 = self._softmax(A3)\n",
    "        return np.argmax(Z3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape((X_train.shape[0], -1)) / 255.0\n",
    "X_test = X_test.reshape((X_test.shape[0], -1)) / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.304662455570403\n",
      "Epoch 2/10, Loss: 2.3050963422029698\n",
      "Epoch 3/10, Loss: 2.3031641949545265\n",
      "Epoch 4/10, Loss: 2.3050799579728\n",
      "Epoch 5/10, Loss: 2.3047547670162962\n",
      "Epoch 6/10, Loss: 2.302021522781697\n",
      "Epoch 7/10, Loss: 2.2959677239305245\n",
      "Epoch 8/10, Loss: 2.290299685929612\n",
      "Epoch 9/10, Loss: 2.2535367350531685\n",
      "Epoch 10/10, Loss: 1.9808930008262\n",
      "Test Accuracy: 0.2911\n"
     ]
    }
   ],
   "source": [
    "# Create the neural network classifier\n",
    "clf = ScratchSimpleNeuralNetworkClassifier(verbose=True)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train_one_hot, X_val=X_test, y_val=y_test_one_hot, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a couple of images with their predicted labels\n",
    "def display_images(X, y_true, y_pred, num_images=2):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i+1)\n",
    "        plt.imshow(X[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'True: {y_true[i]}, Pred: {y_pred[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_images(X_test, y_test, y_pred, num_images=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
