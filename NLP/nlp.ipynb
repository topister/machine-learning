{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Problem 1] Scratch implementation of BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentences\n",
    "sentences = [\n",
    "    \"This movie is SOOOO funny!!!\",\n",
    "    \"What a movie! I never\",\n",
    "    \"best movie ever!!!!! this movie\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess sentences: lowercasing and tokenization\n",
    "def preprocess(sentences):\n",
    "    sentences = [sentence.lower() for sentence in sentences]\n",
    "    tokenized_sentences = [sentence.split() for sentence in sentences]\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n-grams\n",
    "def generate_ngrams(tokenized_sentences, n):\n",
    "    ngrams_list = []\n",
    "    for sentence in tokenized_sentences:\n",
    "        ngrams = zip(*[sentence[i:] for i in range(n)])\n",
    "        ngrams_list.append([\" \".join(ngram) for ngram in ngrams])\n",
    "    return ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW with 1-gram and 2-gram\n",
    "tokenized_sentences = preprocess(sentences)\n",
    "unigrams = generate_ngrams(tokenized_sentences, 1)\n",
    "bigrams = generate_ngrams(tokenized_sentences, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the lists\n",
    "all_unigrams = list(chain.from_iterable(unigrams))\n",
    "all_bigrams = list(chain.from_iterable(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency of unigrams and bigrams\n",
    "unigram_counts = Counter(all_unigrams)\n",
    "bigram_counts = Counter(all_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts: Counter({'movie': 3, 'this': 2, 'is': 1, 'soooo': 1, 'funny!!!': 1, 'what': 1, 'a': 1, 'movie!': 1, 'i': 1, 'never': 1, 'best': 1, 'ever!!!!!': 1})\n",
      "Bigram Counts: Counter({'this movie': 2, 'movie is': 1, 'is soooo': 1, 'soooo funny!!!': 1, 'what a': 1, 'a movie!': 1, 'movie! i': 1, 'i never': 1, 'best movie': 1, 'movie ever!!!!!': 1, 'ever!!!!! this': 1})\n"
     ]
    }
   ],
   "source": [
    "# Display the counts\n",
    "print(\"Unigram Counts:\", unigram_counts)\n",
    "print(\"Bigram Counts:\", bigram_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Problem 2] TF-IDF calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/topister/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"This movie is SOOOO funny!!!\",\n",
    "    \"What a movie! I never\",\n",
    "    \"Best movie ever!!!!! this movie\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert documents to BoW representation using CountVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=stop_words, max_features=5000)\n",
    "bow_matrix = count_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform BoW to TF-IDF using TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(norm=None)\n",
    "tfidf_matrix = tfidf_transformer.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the matrix to a DataFrame for better readability\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>funny</th>\n",
       "      <th>movie</th>\n",
       "      <th>never</th>\n",
       "      <th>soooo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       best      ever     funny  movie     never     soooo\n",
       "0  0.000000  0.000000  1.693147    1.0  0.000000  1.693147\n",
       "1  0.000000  0.000000  0.000000    1.0  1.693147  0.000000\n",
       "2  1.693147  1.693147  0.000000    2.0  0.000000  0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Problem 3] Learning with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_sentences = [\n",
    "    \"I loved the movie, it was fantastic!\",\n",
    "    \"The movie was terrible, I hated it.\",\n",
    "    \"An amazing experience, would watch again.\",\n",
    "    \"Not my type, didn't enjoy it.\",\n",
    "    \"Great film, very entertaining.\",\n",
    "    \"Waste of time, awful movie.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_labels = [1, 0, 1, 0, 1, 0]  # 1 for positive, 0 for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Vectorize using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, max_features=5000)\n",
    "X = vectorizer.fit_transform(imdb_sentences).toarray()\n",
    "y = np.array(imdb_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Scratch mounting of TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "documents = [\n",
    "    \"This movie is SOOOO funny!!!\",\n",
    "    \"What a movie! I never\",\n",
    "    \"best movie ever!!!!! this movie\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and normalization\n",
    "def tokenize(doc):\n",
    "    return doc.lower().split()\n",
    "\n",
    "tokenized_docs = [tokenize(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute term frequencies (TF)\n",
    "def compute_tf(doc):\n",
    "    tf_dict = Counter(doc)\n",
    "    total_terms = len(doc)\n",
    "    for term in tf_dict:\n",
    "        tf_dict[term] = tf_dict[term] / total_terms\n",
    "    return tf_dict\n",
    "\n",
    "tf_list = [compute_tf(doc) for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute document frequencies (DF)\n",
    "def compute_df(docs):\n",
    "    df_dict = {}\n",
    "    for doc in docs:\n",
    "        for term in set(doc):\n",
    "            if term not in df_dict:\n",
    "                df_dict[term] = 1\n",
    "            else:\n",
    "                df_dict[term] += 1\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = compute_df(tokenized_docs)\n",
    "N = len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IDF\n",
    "def compute_idf(df_dict, N):\n",
    "    idf_dict = {}\n",
    "    for term, df in df_dict.items():\n",
    "        idf_dict[term] = np.log(N / df)\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict_standard = compute_idf(df_dict, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf_sklearn(df_dict, N):\n",
    "    idf_dict = {}\n",
    "    for term, df in df_dict.items():\n",
    "        idf_dict[term] = np.log((1 + N) / (1 + df)) + 1\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict_sklearn = compute_idf_sklearn(df_dict, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF\n",
    "def compute_tfidf(tf, idf):\n",
    "    tfidf_dict = {}\n",
    "    for term, tf_val in tf.items():\n",
    "        tfidf_dict[term] = tf_val * idf[term]\n",
    "    return tfidf_dict\n",
    "\n",
    "tfidf_standard = [compute_tfidf(tf, idf_dict_standard) for tf in tf_list]\n",
    "tfidf_sklearn = [compute_tfidf(tf, idf_dict_sklearn) for tf in tf_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF (Standard):\n",
      "       this     movie        is     soooo  funny!!!      what         a  \\\n",
      "0  0.081093  0.081093  0.219722  0.219722  0.219722  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.219722  0.219722   \n",
      "2  0.081093  0.162186  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "     movie!         i     never      best  ever!!!!!  \n",
      "0  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "1  0.219722  0.219722  0.219722  0.000000   0.000000  \n",
      "2  0.000000  0.000000  0.000000  0.219722   0.219722  \n",
      "\n",
      "TF-IDF (Scikit-learn):\n",
      "       this     movie        is     soooo  funny!!!      what         a  \\\n",
      "0  0.257536  0.257536  0.338629  0.338629  0.338629  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.338629  0.338629   \n",
      "2  0.257536  0.515073  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "     movie!         i     never      best  ever!!!!!  \n",
      "0  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "1  0.338629  0.338629  0.338629  0.000000   0.000000  \n",
      "2  0.000000  0.000000  0.000000  0.338629   0.338629  \n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "def display_tfidf(tfidf_list, label):\n",
    "    print(f\"\\nTF-IDF ({label}):\")\n",
    "    df = pd.DataFrame(tfidf_list).fillna(0)\n",
    "    print(df)\n",
    "\n",
    "display_tfidf(tfidf_standard, \"Standard\")\n",
    "display_tfidf(tfidf_sklearn, \"Scikit-learn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Problem 5] Pre-processing of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Split into tokens\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'movie', 'is', 'soooo', 'funny'], ['what', 'a', 'movie', 'i', 'never'], ['best', 'movie', 'ever', 'this', 'movie']]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_docs = [preprocess_text(doc) for doc in documents]\n",
    "print(preprocessed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Learning Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary List : ['movie', 'this', 'ever', 'best', 'never', 'i', 'a', 'what', 'funny', 'soooo', 'is']\n",
      "movie vector: \n",
      "[-0.00536237  0.00236436  0.05103445  0.09009442 -0.09303124 -0.07116942\n",
      "  0.06458993  0.08973157 -0.05015522 -0.03763442]\n",
      "this vector: \n",
      "[ 0.07380505 -0.01533471 -0.04536613  0.06554051 -0.0486016  -0.01816018\n",
      "  0.0287658   0.00991874 -0.08285215 -0.09448818]\n",
      "ever vector: \n",
      "[ 0.07311766  0.05070262  0.06757693  0.00762866  0.06350891 -0.03405366\n",
      " -0.00946401  0.05768573 -0.07521638 -0.03936104]\n",
      "best vector: \n",
      "[-0.07511719 -0.00930061  0.09538261 -0.07319367 -0.02333746 -0.01937727\n",
      "  0.08077542 -0.0593107   0.00045199 -0.04753796]\n",
      "never vector: \n",
      "[-0.0960355   0.05007293 -0.08759586 -0.04391825 -0.000351   -0.00296181\n",
      " -0.0766124   0.09614743  0.04982058  0.09233143]\n",
      "i vector: \n",
      "[-0.08157917  0.04495798 -0.04137076  0.00824536  0.08498619 -0.04462177\n",
      "  0.045175   -0.0678696  -0.03548489  0.09398508]\n",
      "a vector: \n",
      "[-0.01577653  0.00321372 -0.0414063  -0.07682689 -0.01508008  0.02469795\n",
      " -0.00888027  0.05533662 -0.02742977  0.02260065]\n",
      "what vector: \n",
      "[ 0.05455794  0.08345953 -0.01453741 -0.09208143  0.04370552  0.00571785\n",
      "  0.07441908 -0.00813283 -0.02638414 -0.08753009]\n",
      "funny vector: \n",
      "[-0.00856557  0.02826563  0.05401429  0.07052656 -0.05703121  0.0185882\n",
      "  0.06088864 -0.04798051 -0.03107261  0.0679763 ]\n",
      "soooo vector: \n",
      "[ 0.01631476  0.00189917  0.03473637  0.00217777  0.09618826  0.05060603\n",
      " -0.0891739  -0.0704156   0.00901456  0.06392534]\n",
      "is vector: \n",
      "[-0.08619688  0.03665738  0.05189884  0.05741938  0.07466918 -0.06167675\n",
      "  0.01105614  0.06047282 -0.0284005  -0.06173522]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Preprocessed sentences\n",
    "sentences = preprocessed_docs\n",
    "\n",
    "# Initialize and train the Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=10, window=5, min_count=1, sg=0)  # sg=0 means CBoW, sg=1 means Skip-gram\n",
    "\n",
    "# Print the vocabulary and their vectors\n",
    "print(\"Vocabulary List : {}\".format(model.wv.index_to_key))\n",
    "\n",
    "for vocab in model.wv.index_to_key:\n",
    "    print(\"{} vector: \\n{}\".format(vocab, model.wv[vocab]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Problem 7] (Advance assignment) Vector Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of words and their vectors\n",
    "vocabs = list(model.wv.index_to_key)\n",
    "vectors = model.wv[vocabs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use t-SNE to reduce the dimensions to 2 with adjusted perplexity\n",
    "tsne_model = TSNE(perplexity=5, n_components=2, init='pca', n_iter=5000, random_state=23)\n",
    "vectors_tsne = tsne_model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the t-SNE results\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(vectors_tsne[:, 0], vectors_tsne[:, 1])\n",
    "\n",
    "for i, word in enumerate(vocabs):\n",
    "    ax.annotate(word, xy=(vectors_tsne[i, 0], vectors_tsne[i, 1]))\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'movie':\n",
      "this: 0.5436\n",
      "is: 0.4318\n",
      "funny: 0.3793\n"
     ]
    }
   ],
   "source": [
    "# Find similar words\n",
    "similar_words = model.wv.most_similar(positive=[\"movie\"], topn=3)\n",
    "print(\"Words similar to 'movie':\")\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Assuming imdb_data is a DataFrame with 'review' and 'sentiment' columns\n",
    "\n",
    "# Example IMDB data (replace this with actual dataset loading)\n",
    "imdb_data = pd.DataFrame({\n",
    "    'review': [\"This movie is great!\", \"Worst movie ever.\", \"Loved it!\", \"Not good at all.\", \"Absolutely fantastic!\"],\n",
    "    'sentiment': [\"positive\", \"negative\", \"positive\", \"negative\", \"positive\"]\n",
    "})\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Preprocess the reviews\n",
    "imdb_data['review'] = imdb_data['review'].apply(preprocess_text)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "imdb_data['review'] = imdb_data['review'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Function to get the average vector for a review\n",
    "def get_review_vector(review, model):\n",
    "    word_vectors = [model.wv[word] for word in review if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Convert reviews to vectors\n",
    "X = np.array([get_review_vector(review, model) for review in imdb_data['review']])\n",
    "y = imdb_data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n",
      "Accuracy with GloVe: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained GloVe vectors\n",
    "glove_vectors = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "# Function to get the average vector for a review using GloVe vectors\n",
    "def get_review_vector_glove(review, glove_model):\n",
    "    word_vectors = [glove_model[word] for word in review if word in glove_model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(glove_model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Convert reviews to vectors\n",
    "X_glove = np.array([get_review_vector_glove(review, glove_vectors) for review in imdb_data['review']])\n",
    "\n",
    "# Split the data\n",
    "X_train_glove, X_test_glove, y_train_glove, y_test_glove = train_test_split(X_glove, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier\n",
    "classifier_glove = LogisticRegression()\n",
    "classifier_glove.fit(X_train_glove, y_train_glove)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_glove = classifier_glove.predict(X_test_glove)\n",
    "accuracy_glove = accuracy_score(y_test_glove, y_pred_glove)\n",
    "print(\"Accuracy with GloVe: {:.2f}%\".format(accuracy_glove * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
