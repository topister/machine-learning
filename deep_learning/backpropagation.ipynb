def backward_propagation(x, target, learnrate, hidden_layer_out, output_layer_out, weights_hidden_to_output):
    """
    Make a backward pass through the network
    """
    # Calculate output error
    error = target - output_layer_out

    # Calculate error term for output layer
    output_error_term = error  *output_layer_out*  (1 - output_layer_out)

    # Calculate error term for hidden layer
    hidden_error_term = output_error_term  *weights_hidden_to_output*  \
                    hidden_layer_out * (1 - hidden_layer_out)

    # Calculate change in weights for hidden layer to output layer
    delta_w_h_o = learnrate  *output_error_term*  hidden_layer_out

    # Calculate change in weights for input layer to hidden layer
    delta_w_i_h = learnrate  *hidden_error_term*  x[:, None]

    return delta_w_h_o, delta_w_i_h
